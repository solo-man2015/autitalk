{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO89nipTzJ4/ESGMpHMJR6F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/solo-man2015/autitalk/blob/main/Autitalk_with_Agentic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HoZUBxXatBq7",
        "outputId": "02b49459-1b09-4782-d8d0-06eb13392a21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting crewai\n",
            "  Downloading crewai-1.7.2-py3-none-any.whl.metadata (36 kB)\n",
            "Collecting langchain_google_genai\n",
            "  Downloading langchain_google_genai-4.1.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting aiosqlite~=0.21.0 (from crewai)\n",
            "  Downloading aiosqlite-0.21.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting appdirs~=1.4.4 (from crewai)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting chromadb~=1.1.0 (from crewai)\n",
            "  Downloading chromadb-1.1.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
            "Collecting click~=8.1.7 (from crewai)\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting instructor>=1.3.3 (from crewai)\n",
            "  Downloading instructor-1.13.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting json-repair~=0.25.2 (from crewai)\n",
            "  Downloading json_repair-0.25.3-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting json5~=0.10.0 (from crewai)\n",
            "  Downloading json5-0.10.0-py3-none-any.whl.metadata (34 kB)\n",
            "Collecting jsonref~=1.1.0 (from crewai)\n",
            "  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting mcp~=1.16.0 (from crewai)\n",
            "  Downloading mcp-1.16.0-py3-none-any.whl.metadata (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.4/80.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai~=1.83.0 (from crewai)\n",
            "  Downloading openai-1.83.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: openpyxl~=3.1.5 in /usr/local/lib/python3.12/dist-packages (from crewai) (3.1.5)\n",
            "Collecting opentelemetry-api~=1.34.0 (from crewai)\n",
            "  Downloading opentelemetry_api-1.34.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http~=1.34.0 (from crewai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.34.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk~=1.34.0 (from crewai)\n",
            "  Downloading opentelemetry_sdk-1.34.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting pdfplumber~=0.11.4 (from crewai)\n",
            "  Downloading pdfplumber-0.11.8-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker~=2.7.0 (from crewai)\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting pydantic-settings~=2.10.1 (from crewai)\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting pydantic~=2.11.9 (from crewai)\n",
            "  Downloading pydantic-2.11.10-py3-none-any.whl.metadata (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.6/68.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyjwt~=2.9.0 (from crewai)\n",
            "  Downloading PyJWT-2.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting python-dotenv~=1.1.1 (from crewai)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting regex~=2024.9.11 (from crewai)\n",
            "  Downloading regex-2024.9.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers~=0.20.3 (from crewai)\n",
            "  Downloading tokenizers-0.20.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting tomli-w~=1.1.0 (from crewai)\n",
            "  Downloading tomli_w-1.1.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting tomli~=2.0.2 (from crewai)\n",
            "  Downloading tomli-2.0.2-py3-none-any.whl.metadata (10.0 kB)\n",
            "Collecting uv~=0.9.13 (from crewai)\n",
            "  Downloading uv-0.9.21-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain_google_genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-genai<2.0.0,>=1.56.0 (from langchain_google_genai)\n",
            "  Downloading google_genai-1.56.0-py3-none-any.whl.metadata (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.3/53.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<2.0.0,>=1.2.2 (from langchain_google_genai)\n",
            "  Downloading langchain_core-1.2.5-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.12/dist-packages (from aiosqlite~=0.21.0->crewai) (4.15.0)\n",
            "Collecting build>=1.0.3 (from chromadb~=1.1.0->crewai)\n",
            "  Downloading build-1.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting pybase64>=1.4.1 (from chromadb~=1.1.0->crewai)\n",
            "  Downloading pybase64-1.4.3-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb~=1.1.0->crewai) (0.38.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (2.0.2)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb~=1.1.0->crewai)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb~=1.1.0->crewai)\n",
            "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb~=1.1.0->crewai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.39.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting pypika>=0.48.9 (from chromadb~=1.1.0->crewai)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (1.76.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb~=1.1.0->crewai)\n",
            "  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (0.20.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb~=1.1.0->crewai)\n",
            "  Downloading kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (9.1.2)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (6.0.3)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (5.2.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (3.11.5)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (4.25.1)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (4.12.0)\n",
            "Collecting google-auth<3.0.0,>=2.45.0 (from google-auth[requests]<3.0.0,>=2.45.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai)\n",
            "  Downloading google_auth-2.45.0-py2.py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2.32.4)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (15.0.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (1.3.1)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /usr/local/lib/python3.12/dist-packages (from instructor>=1.3.3->crewai) (3.13.2)\n",
            "Collecting diskcache>=5.6.3 (from instructor>=1.3.3->crewai)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.16 in /usr/local/lib/python3.12/dist-packages (from instructor>=1.3.3->crewai) (0.17.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from instructor>=1.3.3->crewai) (3.1.6)\n",
            "Collecting jiter<0.12,>=0.6.1 (from instructor>=1.3.3->crewai)\n",
            "  Downloading jiter-0.11.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "INFO: pip is looking at multiple versions of instructor to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting instructor>=1.3.3 (from crewai)\n",
            "  Downloading instructor-1.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting jiter<0.11,>=0.6.1 (from instructor>=1.3.3->crewai)\n",
            "  Downloading jiter-0.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting pre-commit>=4.3.0 (from instructor>=1.3.3->crewai)\n",
            "  Downloading pre_commit-4.5.1-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from instructor>=1.3.3->crewai) (2.41.4)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.2->langchain_google_genai) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.2->langchain_google_genai) (0.4.59)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.2->langchain_google_genai) (25.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.2->langchain_google_genai) (0.12.0)\n",
            "Requirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.12/dist-packages (from mcp~=1.16.0->crewai) (0.4.3)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.12/dist-packages (from mcp~=1.16.0->crewai) (0.0.20)\n",
            "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from mcp~=1.16.0->crewai) (3.0.4)\n",
            "Requirement already satisfied: starlette>=0.27 in /usr/local/lib/python3.12/dist-packages (from mcp~=1.16.0->crewai) (0.50.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl~=3.1.5->crewai) (2.0.0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api~=1.34.0->crewai) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http~=1.34.0->crewai) (1.72.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.34.1 (from opentelemetry-exporter-otlp-proto-http~=1.34.0->crewai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.34.1 (from opentelemetry-exporter-otlp-proto-http~=1.34.0->crewai)\n",
            "  Downloading opentelemetry_proto-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: protobuf<6.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-proto==1.34.1->opentelemetry-exporter-otlp-proto-http~=1.34.0->crewai) (5.29.5)\n",
            "Collecting opentelemetry-semantic-conventions==0.55b1 (from opentelemetry-sdk~=1.34.0->crewai)\n",
            "  Downloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting pdfminer.six==20251107 (from pdfplumber~=0.11.4->crewai)\n",
            "  Downloading pdfminer_six-20251107-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber~=0.11.4->crewai) (11.3.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber~=0.11.4->crewai)\n",
            "  Downloading pypdfium2-5.2.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251107->pdfplumber~=0.11.4->crewai) (3.4.4)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251107->pdfplumber~=0.11.4->crewai) (43.0.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic~=2.11.9->crewai) (0.7.0)\n",
            "Collecting pydantic-core<3.0.0,>=2.18.0 (from instructor>=1.3.3->crewai)\n",
            "  Downloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic~=2.11.9->crewai) (0.4.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers~=0.20.3->crewai) (0.36.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.3.3->crewai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.3.3->crewai) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.3.3->crewai) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.3.3->crewai) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.3.3->crewai) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.3.3->crewai) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.3.3->crewai) (1.22.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (3.11)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb~=1.1.0->crewai)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.45.0->google-auth[requests]<3.0.0,>=2.45.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (6.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.45.0->google-auth[requests]<3.0.0,>=2.45.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.45.0->google-auth[requests]<3.0.0,>=2.45.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb~=1.1.0->crewai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb~=1.1.0->crewai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb~=1.1.0->crewai) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers~=0.20.3->crewai) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers~=0.20.3->crewai) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers~=0.20.3->crewai) (1.2.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api~=1.34.0->crewai) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2<4.0.0,>=3.1.4->instructor>=1.3.3->crewai) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.2->langchain_google_genai) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb~=1.1.0->crewai) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb~=1.1.0->crewai) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb~=1.1.0->crewai) (0.30.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb~=1.1.0->crewai) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb~=1.1.0->crewai) (2.9.0.post0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb~=1.1.0->crewai) (1.9.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb~=1.1.0->crewai) (2.0.0)\n",
            "Collecting urllib3<2.4.0,>=1.24.2 (from kubernetes>=28.1.0->chromadb~=1.1.0->crewai)\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb~=1.1.0->crewai)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.2->langchain_google_genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.2->langchain_google_genai) (0.25.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb~=1.1.0->crewai)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb~=1.1.0->crewai) (25.9.23)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb~=1.1.0->crewai) (1.14.0)\n",
            "INFO: pip is looking at multiple versions of opentelemetry-exporter-otlp-proto-grpc to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb~=1.1.0->crewai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.39.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.35.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb~=1.1.0->crewai)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting cfgv>=2.0.0 (from pre-commit>=4.3.0->instructor>=1.3.3->crewai)\n",
            "  Downloading cfgv-3.5.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting identify>=1.0.0 (from pre-commit>=4.3.0->instructor>=1.3.3->crewai)\n",
            "  Downloading identify-2.6.15-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting nodeenv>=0.11.1 (from pre-commit>=4.3.0->instructor>=1.3.3->crewai)\n",
            "  Downloading nodeenv-1.10.0-py2.py3-none-any.whl.metadata (24 kB)\n",
            "Collecting virtualenv>=20.10.0 (from pre-commit>=4.3.0->instructor>=1.3.3->crewai)\n",
            "  Downloading virtualenv-20.35.4-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb~=1.1.0->crewai) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb~=1.1.0->crewai) (2.19.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb~=1.1.0->crewai) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb~=1.1.0->crewai)\n",
            "  Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb~=1.1.0->crewai)\n",
            "  Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb~=1.1.0->crewai)\n",
            "  Downloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber~=0.11.4->crewai) (2.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb~=1.1.0->crewai) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.45.0->google-auth[requests]<3.0.0,>=2.45.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.6.1)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit>=4.3.0->instructor>=1.3.3->crewai)\n",
            "  Downloading distlib-0.4.0-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.12/dist-packages (from virtualenv>=20.10.0->pre-commit>=4.3.0->instructor>=1.3.3->crewai) (4.5.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb~=1.1.0->crewai)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb~=1.1.0->crewai) (3.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb~=1.1.0->crewai) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber~=0.11.4->crewai) (2.23)\n",
            "Downloading crewai-1.7.2-py3-none-any.whl (666 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m666.8/666.8 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_genai-4.1.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiosqlite-0.21.0-py3-none-any.whl (15 kB)\n",
            "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading chromadb-1.1.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.9/19.9 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_genai-1.56.0-py3-none-any.whl (426 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.6/426.6 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading instructor-1.12.0-py3-none-any.whl (157 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.9/157.9 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json_repair-0.25.3-py3-none-any.whl (12 kB)\n",
            "Downloading json5-0.10.0-py3-none-any.whl (34 kB)\n",
            "Downloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
            "Downloading langchain_core-1.2.5-py3-none-any.whl (484 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m484.9/484.9 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mcp-1.16.0-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.3/167.3 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.83.0-py3-none-any.whl (723 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m723.4/723.4 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.34.1-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_http-1.34.1-py3-none-any.whl (17 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.34.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.34.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl (196 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfplumber-0.11.8-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20251107-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m106.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading pydantic-2.11.10-py3-none-any.whl (444 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.8/444.8 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyJWT-2.9.0-py3-none-any.whl (22 kB)\n",
            "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading regex-2024.9.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (797 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.0/797.0 kB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.20.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomli-2.0.2-py3-none-any.whl (13 kB)\n",
            "Downloading tomli_w-1.1.0-py3-none-any.whl (6.4 kB)\n",
            "Downloading uv-0.9.21-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.3.0-py3-none-any.whl (23 kB)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth-2.45.0-py2.py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.3/233.3 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.0/352.0 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl (18 kB)\n",
            "Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pre_commit-4.5.1-py2.py3-none-any.whl (226 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.4/226.4 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.3-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-5.2.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading cfgv-3.5.0-py2.py3-none-any.whl (7.4 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (517 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading identify-2.6.15-py2.py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nodeenv-1.10.0-py2.py3-none-any.whl (23 kB)\n",
            "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading virtualenv-20.35.4-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m112.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading distlib-0.4.0-py2.py3-none-any.whl (469 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=85f1ef92b529a21cdce523577afc37e57e992f0dfc1c3c8308680a2d8f896a58\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, filetype, durationpy, distlib, appdirs, virtualenv, uvloop, uv, urllib3, tomli-w, tomli, regex, python-dotenv, pyproject_hooks, pypdfium2, pyjwt, pydantic-core, pybase64, portalocker, opentelemetry-proto, nodeenv, jsonref, json5, json-repair, jiter, identify, humanfriendly, httptools, diskcache, click, cfgv, bcrypt, backoff, aiosqlite, watchfiles, pydantic, pre-commit, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, google-auth, coloredlogs, build, pydantic-settings, posthog, pdfminer.six, opentelemetry-semantic-conventions, openai, onnxruntime, tokenizers, pdfplumber, opentelemetry-sdk, mcp, kubernetes, instructor, google-genai, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, langchain-core, langchain_google_genai, chromadb, crewai\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2025.11.3\n",
            "    Uninstalling regex-2025.11.3:\n",
            "      Successfully uninstalled regex-2025.11.3\n",
            "  Attempting uninstall: python-dotenv\n",
            "    Found existing installation: python-dotenv 1.2.1\n",
            "    Uninstalling python-dotenv-1.2.1:\n",
            "      Successfully uninstalled python-dotenv-1.2.1\n",
            "  Attempting uninstall: pyjwt\n",
            "    Found existing installation: PyJWT 2.10.1\n",
            "    Uninstalling PyJWT-2.10.1:\n",
            "      Successfully uninstalled PyJWT-2.10.1\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.41.4\n",
            "    Uninstalling pydantic_core-2.41.4:\n",
            "      Successfully uninstalled pydantic_core-2.41.4\n",
            "  Attempting uninstall: opentelemetry-proto\n",
            "    Found existing installation: opentelemetry-proto 1.37.0\n",
            "    Uninstalling opentelemetry-proto-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-proto-1.37.0\n",
            "  Attempting uninstall: jiter\n",
            "    Found existing installation: jiter 0.12.0\n",
            "    Uninstalling jiter-0.12.0:\n",
            "      Successfully uninstalled jiter-0.12.0\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.3.1\n",
            "    Uninstalling click-8.3.1:\n",
            "      Successfully uninstalled click-8.3.1\n",
            "  Attempting uninstall: aiosqlite\n",
            "    Found existing installation: aiosqlite 0.22.0\n",
            "    Uninstalling aiosqlite-0.22.0:\n",
            "      Successfully uninstalled aiosqlite-0.22.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.12.3\n",
            "    Uninstalling pydantic-2.12.3:\n",
            "      Successfully uninstalled pydantic-2.12.3\n",
            "  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n",
            "    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.37.0\n",
            "    Uninstalling opentelemetry-exporter-otlp-proto-common-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.37.0\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.37.0\n",
            "    Uninstalling opentelemetry-api-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.37.0\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 2.43.0\n",
            "    Uninstalling google-auth-2.43.0:\n",
            "      Successfully uninstalled google-auth-2.43.0\n",
            "  Attempting uninstall: pydantic-settings\n",
            "    Found existing installation: pydantic-settings 2.12.0\n",
            "    Uninstalling pydantic-settings-2.12.0:\n",
            "      Successfully uninstalled pydantic-settings-2.12.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.58b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.58b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.58b0\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 2.12.0\n",
            "    Uninstalling openai-2.12.0:\n",
            "      Successfully uninstalled openai-2.12.0\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.1\n",
            "    Uninstalling tokenizers-0.22.1:\n",
            "      Successfully uninstalled tokenizers-0.22.1\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.37.0\n",
            "    Uninstalling opentelemetry-sdk-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.37.0\n",
            "  Attempting uninstall: mcp\n",
            "    Found existing installation: mcp 1.24.0\n",
            "    Uninstalling mcp-1.24.0:\n",
            "      Successfully uninstalled mcp-1.24.0\n",
            "  Attempting uninstall: google-genai\n",
            "    Found existing installation: google-genai 1.55.0\n",
            "    Uninstalling google-genai-1.55.0:\n",
            "      Successfully uninstalled google-genai-1.55.0\n",
            "  Attempting uninstall: opentelemetry-exporter-otlp-proto-http\n",
            "    Found existing installation: opentelemetry-exporter-otlp-proto-http 1.37.0\n",
            "    Uninstalling opentelemetry-exporter-otlp-proto-http-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-exporter-otlp-proto-http-1.37.0\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 1.2.1\n",
            "    Uninstalling langchain-core-1.2.1:\n",
            "      Successfully uninstalled langchain-core-1.2.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires google-auth==2.43.0, but you have google-auth 2.45.0 which is incompatible.\n",
            "opentelemetry-exporter-gcp-logging 1.11.0a0 requires opentelemetry-api>=1.35.0, but you have opentelemetry-api 1.34.1 which is incompatible.\n",
            "opentelemetry-exporter-gcp-logging 1.11.0a0 requires opentelemetry-sdk<1.39.0,>=1.35.0, but you have opentelemetry-sdk 1.34.1 which is incompatible.\n",
            "google-adk 1.21.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.34.1 which is incompatible.\n",
            "google-adk 1.21.0 requires opentelemetry-exporter-otlp-proto-http>=1.36.0, but you have opentelemetry-exporter-otlp-proto-http 1.34.1 which is incompatible.\n",
            "google-adk 1.21.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.34.1 which is incompatible.\n",
            "transformers 4.57.3 requires tokenizers<=0.23.0,>=0.22.0, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiosqlite-0.21.0 appdirs-1.4.4 backoff-2.2.1 bcrypt-5.0.0 build-1.3.0 cfgv-3.5.0 chromadb-1.1.1 click-8.1.8 coloredlogs-15.0.1 crewai-1.7.2 diskcache-5.6.3 distlib-0.4.0 durationpy-0.10 filetype-1.2.0 google-auth-2.45.0 google-genai-1.56.0 httptools-0.7.1 humanfriendly-10.0 identify-2.6.15 instructor-1.12.0 jiter-0.10.0 json-repair-0.25.3 json5-0.10.0 jsonref-1.1.0 kubernetes-34.1.0 langchain-core-1.2.5 langchain_google_genai-4.1.2 mcp-1.16.0 nodeenv-1.10.0 onnxruntime-1.23.2 openai-1.83.0 opentelemetry-api-1.34.1 opentelemetry-exporter-otlp-proto-common-1.34.1 opentelemetry-exporter-otlp-proto-grpc-1.34.1 opentelemetry-exporter-otlp-proto-http-1.34.1 opentelemetry-proto-1.34.1 opentelemetry-sdk-1.34.1 opentelemetry-semantic-conventions-0.55b1 pdfminer.six-20251107 pdfplumber-0.11.8 portalocker-2.7.0 posthog-5.4.0 pre-commit-4.5.1 pybase64-1.4.3 pydantic-2.11.10 pydantic-core-2.33.2 pydantic-settings-2.10.1 pyjwt-2.9.0 pypdfium2-5.2.0 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.1.1 regex-2024.9.11 tokenizers-0.20.3 tomli-2.0.2 tomli-w-1.1.0 urllib3-2.3.0 uv-0.9.21 uvloop-0.22.1 virtualenv-20.35.4 watchfiles-1.1.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "0c150a41df9b402095acb2390fa0c2ae"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install crewai langchain_google_genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2306d8e"
      },
      "source": [
        "To use the Google Gemini API, you'll need an API key. If you don't already have one, create a key in [Google AI Studio](https://makersuite.google.com/app/apikey).\n",
        "\n",
        "In Colab, add the key to the secrets manager under the \"🔑\" icon in the left panel. Give it the name `GOOGLE_API_KEY`. Then, we'll set up the environment variable for `crewai`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1f48cd0"
      },
      "source": [
        "# Used to securely store your API key\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Set the GOOGLE_API_KEY environment variable from Colab secrets\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install crewai langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKtpi1tIL6d1",
        "outputId": "7676775a-b7f3-4d1e-b969-e14fff58be88"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: crewai in /usr/local/lib/python3.12/dist-packages (1.7.2)\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.12/dist-packages (4.1.2)\n",
            "Requirement already satisfied: aiosqlite~=0.21.0 in /usr/local/lib/python3.12/dist-packages (from crewai) (0.21.0)\n",
            "Requirement already satisfied: appdirs~=1.4.4 in /usr/local/lib/python3.12/dist-packages (from crewai) (1.4.4)\n",
            "Requirement already satisfied: chromadb~=1.1.0 in /usr/local/lib/python3.12/dist-packages (from crewai) (1.1.1)\n",
            "Requirement already satisfied: click~=8.1.7 in /usr/local/lib/python3.12/dist-packages (from crewai) (8.1.8)\n",
            "Requirement already satisfied: instructor>=1.3.3 in /usr/local/lib/python3.12/dist-packages (from crewai) (1.12.0)\n",
            "Requirement already satisfied: json-repair~=0.25.2 in /usr/local/lib/python3.12/dist-packages (from crewai) (0.25.3)\n",
            "Requirement already satisfied: json5~=0.10.0 in /usr/local/lib/python3.12/dist-packages (from crewai) (0.10.0)\n",
            "Requirement already satisfied: jsonref~=1.1.0 in /usr/local/lib/python3.12/dist-packages (from crewai) (1.1.0)\n",
            "Requirement already satisfied: mcp~=1.16.0 in /usr/local/lib/python3.12/dist-packages (from crewai) (1.16.0)\n",
            "Requirement already satisfied: openai~=1.83.0 in /usr/local/lib/python3.12/dist-packages (from crewai) (1.83.0)\n",
            "Requirement already satisfied: openpyxl~=3.1.5 in /usr/local/lib/python3.12/dist-packages (from crewai) (3.1.5)\n",
            "Requirement already satisfied: opentelemetry-api~=1.34.0 in /usr/local/lib/python3.12/dist-packages (from crewai) (1.34.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http~=1.34.0 in /usr/local/lib/python3.12/dist-packages (from crewai) (1.34.1)\n",
            "Requirement already satisfied: opentelemetry-sdk~=1.34.0 in /usr/local/lib/python3.12/dist-packages (from crewai) (1.34.1)\n",
            "Requirement already satisfied: pdfplumber~=0.11.4 in /usr/local/lib/python3.12/dist-packages (from crewai) (0.11.8)\n",
            "Requirement already satisfied: portalocker~=2.7.0 in /usr/local/lib/python3.12/dist-packages (from crewai) (2.7.0)\n",
            "Requirement already satisfied: pydantic-settings~=2.10.1 in /usr/local/lib/python3.12/dist-packages (from crewai) (2.10.1)\n",
            "Requirement already satisfied: pydantic~=2.11.9 in /usr/local/lib/python3.12/dist-packages (from crewai) (2.11.10)\n",
            "Requirement already satisfied: pyjwt~=2.9.0 in /usr/local/lib/python3.12/dist-packages (from crewai) (2.9.0)\n",
            "Requirement already satisfied: python-dotenv~=1.1.1 in /usr/local/lib/python3.12/dist-packages (from crewai) (1.1.1)\n",
            "Requirement already satisfied: regex~=2024.9.11 in /usr/local/lib/python3.12/dist-packages (from crewai) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers~=0.20.3 in /usr/local/lib/python3.12/dist-packages (from crewai) (0.20.3)\n",
            "Requirement already satisfied: tomli-w~=1.1.0 in /usr/local/lib/python3.12/dist-packages (from crewai) (1.1.0)\n",
            "Requirement already satisfied: tomli~=2.0.2 in /usr/local/lib/python3.12/dist-packages (from crewai) (2.0.2)\n",
            "Requirement already satisfied: uv~=0.9.13 in /usr/local/lib/python3.12/dist-packages (from crewai) (0.9.21)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.56.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.56.0)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.2.5)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.12/dist-packages (from aiosqlite~=0.21.0->crewai) (4.15.0)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (1.3.0)\n",
            "Requirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (1.4.3)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb~=1.1.0->crewai) (0.38.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (2.0.2)\n",
            "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (5.4.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (1.23.2)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (1.34.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (1.76.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (5.0.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (0.20.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (34.1.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (9.1.2)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (6.0.3)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (5.2.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (3.11.5)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (4.25.1)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (4.12.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.45.0 in /usr/local/lib/python3.12/dist-packages (from google-auth[requests]<3.0.0,>=2.45.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.45.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.32.4)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (15.0.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.3.1)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /usr/local/lib/python3.12/dist-packages (from instructor>=1.3.3->crewai) (3.13.2)\n",
            "Requirement already satisfied: diskcache>=5.6.3 in /usr/local/lib/python3.12/dist-packages (from instructor>=1.3.3->crewai) (5.6.3)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.16 in /usr/local/lib/python3.12/dist-packages (from instructor>=1.3.3->crewai) (0.17.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from instructor>=1.3.3->crewai) (3.1.6)\n",
            "Requirement already satisfied: jiter<0.11,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from instructor>=1.3.3->crewai) (0.10.0)\n",
            "Requirement already satisfied: pre-commit>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from instructor>=1.3.3->crewai) (4.5.1)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from instructor>=1.3.3->crewai) (2.33.2)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.2->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.2->langchain-google-genai) (0.4.59)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.2->langchain-google-genai) (25.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.2->langchain-google-genai) (0.12.0)\n",
            "Requirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.12/dist-packages (from mcp~=1.16.0->crewai) (0.4.3)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.12/dist-packages (from mcp~=1.16.0->crewai) (0.0.20)\n",
            "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from mcp~=1.16.0->crewai) (3.0.4)\n",
            "Requirement already satisfied: starlette>=0.27 in /usr/local/lib/python3.12/dist-packages (from mcp~=1.16.0->crewai) (0.50.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl~=3.1.5->crewai) (2.0.0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api~=1.34.0->crewai) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http~=1.34.0->crewai) (1.72.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.34.1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http~=1.34.0->crewai) (1.34.1)\n",
            "Requirement already satisfied: opentelemetry-proto==1.34.1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http~=1.34.0->crewai) (1.34.1)\n",
            "Requirement already satisfied: protobuf<6.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-proto==1.34.1->opentelemetry-exporter-otlp-proto-http~=1.34.0->crewai) (5.29.5)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.55b1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk~=1.34.0->crewai) (0.55b1)\n",
            "Requirement already satisfied: pdfminer.six==20251107 in /usr/local/lib/python3.12/dist-packages (from pdfplumber~=0.11.4->crewai) (20251107)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber~=0.11.4->crewai) (11.3.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.12/dist-packages (from pdfplumber~=0.11.4->crewai) (5.2.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251107->pdfplumber~=0.11.4->crewai) (3.4.4)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251107->pdfplumber~=0.11.4->crewai) (43.0.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic~=2.11.9->crewai) (0.7.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic~=2.11.9->crewai) (0.4.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers~=0.20.3->crewai) (0.36.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.3.3->crewai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.3.3->crewai) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.3.3->crewai) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.3.3->crewai) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.3.3->crewai) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.3.3->crewai) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.3.3->crewai) (1.22.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (3.11)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb~=1.1.0->crewai) (1.2.0)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.45.0->google-auth[requests]<3.0.0,>=2.45.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (6.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.45.0->google-auth[requests]<3.0.0,>=2.45.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.45.0->google-auth[requests]<3.0.0,>=2.45.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb~=1.1.0->crewai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb~=1.1.0->crewai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb~=1.1.0->crewai) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers~=0.20.3->crewai) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers~=0.20.3->crewai) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers~=0.20.3->crewai) (1.2.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api~=1.34.0->crewai) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2<4.0.0,>=3.1.4->instructor>=1.3.3->crewai) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.2->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb~=1.1.0->crewai) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb~=1.1.0->crewai) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb~=1.1.0->crewai) (0.30.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb~=1.1.0->crewai) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb~=1.1.0->crewai) (2.9.0.post0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb~=1.1.0->crewai) (1.9.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb~=1.1.0->crewai) (2.0.0)\n",
            "Requirement already satisfied: urllib3<2.4.0,>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb~=1.1.0->crewai) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb~=1.1.0->crewai) (0.10)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.2->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.2->langchain-google-genai) (0.25.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb~=1.1.0->crewai) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb~=1.1.0->crewai) (25.9.23)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb~=1.1.0->crewai) (1.14.0)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb~=1.1.0->crewai) (2.2.1)\n",
            "Requirement already satisfied: cfgv>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pre-commit>=4.3.0->instructor>=1.3.3->crewai) (3.5.0)\n",
            "Requirement already satisfied: identify>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from pre-commit>=4.3.0->instructor>=1.3.3->crewai) (2.6.15)\n",
            "Requirement already satisfied: nodeenv>=0.11.1 in /usr/local/lib/python3.12/dist-packages (from pre-commit>=4.3.0->instructor>=1.3.3->crewai) (1.10.0)\n",
            "Requirement already satisfied: virtualenv>=20.10.0 in /usr/local/lib/python3.12/dist-packages (from pre-commit>=4.3.0->instructor>=1.3.3->crewai) (20.35.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb~=1.1.0->crewai) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb~=1.1.0->crewai) (2.19.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb~=1.1.0->crewai) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb~=1.1.0->crewai) (0.7.1)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb~=1.1.0->crewai) (0.22.1)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb~=1.1.0->crewai) (1.1.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber~=0.11.4->crewai) (2.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb~=1.1.0->crewai) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.45.0->google-auth[requests]<3.0.0,>=2.45.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.12/dist-packages (from virtualenv>=20.10.0->pre-commit>=4.3.0->instructor>=1.3.3->crewai) (0.4.0)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.12/dist-packages (from virtualenv>=20.10.0->pre-commit>=4.3.0->instructor>=1.3.3->crewai) (4.5.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb~=1.1.0->crewai) (10.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb~=1.1.0->crewai) (3.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb~=1.1.0->crewai) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber~=0.11.4->crewai) (2.23)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iR43cip-MVpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be653d15"
      },
      "source": [
        "# Task\n",
        "Add a code cell to set a dummy `OPENAI_API_KEY` environment variable, then re-execute cell `LrzdQBihMWIx` to initialize the `crewai` agents and crew, and finally re-execute cell `a1e1afd3` to kickoff the crew."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f588088c"
      },
      "source": [
        "## Add_Dummy_OpenAI_Key\n",
        "\n",
        "### Subtask:\n",
        "Add a code cell to set a dummy `OPENAI_API_KEY` environment variable to prevent `crewai` from throwing an ImportError when looking for an OpenAI provider.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da86715d"
      },
      "source": [
        "**Reasoning**:\n",
        "To prevent `crewai` from throwing an ImportError related to `OPENAI_API_KEY`, I will add a code cell to set a dummy key.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79d9cfca",
        "outputId": "5a14a42b-8fe8-45fc-deec-1d0fc128d1d3"
      },
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = 'sk-dummy-key'\n",
        "print(\"Dummy OPENAI_API_KEY set.\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dummy OPENAI_API_KEY set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66abbfb7"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the dummy `OPENAI_API_KEY` is set, I will re-execute cell `LrzdQBihMWIx` to correctly initialize the `crewai` agents and crew with the specified Google Gemini LLM.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bdcb389"
      },
      "source": [
        "# Task\n",
        "Modify cell `LrzdQBihMWIx` to include the `os.environ['OPENAI_API_KEY']` setting at the top. Then, re-execute cell `LrzdQBihMWIx` and cell `a1e1afd3`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5086af1d"
      },
      "source": [
        "## Ensure_OpenAI_Key_Recognized\n",
        "\n",
        "### Subtask:\n",
        "Modify cell `LrzdQBihMWIx` to include the `os.environ['OPENAI_API_KEY']` setting at the top, ensuring `crewai` recognizes it during initialization and resolves the `ImportError`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d72a2fd1"
      },
      "source": [
        "**Reasoning**:\n",
        "To ensure `crewai` recognizes a dummy `OPENAI_API_KEY` during initialization and resolves the `ImportError`, I will modify cell `LrzdQBihMWIx` to add the line `os.environ['OPENAI_API_KEY'] = 'sk-dummy-key'` at its very top, keeping all existing code intact.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e718494"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step updated cell `LrzdQBihMWIx` (now `ce2eabe0`) to include the dummy `OPENAI_API_KEY` setting. Now, I will re-execute cell `ce2eabe0` to ensure the `crewai` agents and crew are properly initialized with the specified Google Gemini LLM, resolving the previous `ImportError`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f23536f"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step updated cell `LrzdQBihMWIx` (now `ce2eabe0`) to include the dummy `OPENAI_API_KEY` setting. Now, I will re-execute cell `ce2eabe0` to ensure the `crewai` agents and crew are properly initialized with the specified Google Gemini LLM, resolving the previous `ImportError`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16c9cea1"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step updated cell `LrzdQBihMWIx` (now `ce2eabe0`) to include the dummy `OPENAI_API_KEY` setting. Now, I will re-execute cell `ce2eabe0` to ensure the `crewai` agents and crew are properly initialized with the specified Google Gemini LLM, resolving the previous `ImportError`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42ffbc27"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step updated cell `LrzdQBihMWIx` (now `ce2eabe0`) to include the dummy `OPENAI_API_KEY` setting. Now, I will re-execute cell `ce2eabe0` to ensure the `crewai` agents and crew are properly initialized with the specified Google Gemini LLM, resolving the previous `ImportError`. This is the same code block as the previous step but is being re-executed as per the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab4668d3"
      },
      "source": [
        "**Reasoning**:\n",
        "The `crewai` agents and crew have been successfully initialized with the specified Google Gemini LLM after setting the dummy `OPENAI_API_KEY`. The next logical step is to re-execute cell `a1e1afd3` to kickoff the crew and start the defined tasks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4aa800d"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempts to set a dummy `OPENAI_API_KEY` to resolve an `ImportError` led to an `AuthenticationError` during `my_crew.kickoff()`. This indicates that `crewai` is still attempting to use an OpenAI client, even when `llm=gemini_llm` is explicitly assigned. To prevent `crewai` from trying to authenticate with OpenAI, the `OPENAI_API_KEY` environment variable should not be set at all if we intend to use only the Google Gemini LLM. Therefore, I will modify cell `ce2eabe0` to remove the line that sets the dummy `OPENAI_API_KEY` and then re-execute it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf4561dd"
      },
      "source": [
        "**Reasoning**:\n",
        "The `ValidationError` indicates that the `GOOGLE_API_KEY` is not set for `ChatGoogleGenerativeAI`. This key is intended to be loaded from Colab secrets and set as an environment variable by executing cell `e1f48cd0`. Executing this cell will make the `GOOGLE_API_KEY` available, allowing the `gemini_llm` to be initialized correctly.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13750d86",
        "outputId": "2fcebbcd-1c4e-4a44-e861-e42855bce42f"
      },
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Set the GOOGLE_API_KEY environment variable from Colab secrets\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n",
        "print(\"GOOGLE_API_KEY set from Colab secrets.\")\n",
        "#os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GOOGLE_API_KEY set from Colab secrets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce354215"
      },
      "source": [
        "**Reasoning**:\n",
        "The `GOOGLE_API_KEY` has now been set from Colab secrets. The next step is to re-execute the code that initializes the `crewai` agents and crew (cell `be4f46dd`) to ensure that `gemini_llm` is correctly initialized with the available API key and without the previous OpenAI API key issues.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04c85a9d"
      },
      "source": [
        "**Reasoning**:\n",
        "The repeated `ImportError: OPENAI_API_KEY is required` despite explicitly assigning `gemini_llm` to agents and crew indicates that `crewai` has a fallback mechanism trying to initialize an OpenAI LLM. To prevent this, I will set a dummy `CREWAI_API_KEY` environment variable to signal to `crewai` that a default LLM is configured, thus bypassing its implicit attempt to load OpenAI, and then re-execute the cell that initializes the agents and crew with the `gemini_llm`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "675a17bc"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step failed with a `SyntaxError` due to a typo in the import statement (`rom crewai import Process`). I will correct `rom` to `from` in the code to fix this syntax error.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a97d1bc"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step failed with a `SyntaxError` due to a typo in the import statement (`rom crewai import Process`). I will correct `rom` to `from` in the code to fix this syntax error.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38cf0365"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous error `ImportError: Error importing native provider: OPENAI_API_KEY is required` indicates that `crewai` internally attempts to load the OpenAI provider and requires the `OPENAI_API_KEY` environment variable to be set, even when a different LLM (Google Gemini) is explicitly assigned to the agents and crew. To resolve this import error, I will re-add a dummy `OPENAI_API_KEY` at the top of the code cell.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcff0d36"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous `ImportError: OPENAI_API_KEY is required` error was addressed by re-adding a dummy `OPENAI_API_KEY`. Now, I will re-execute the cell to initialize the `crewai` agents and crew with the specified Google Gemini LLM, expecting this to resolve the `ImportError` and allow the setup to complete.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57d1e208"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous `ImportError: OPENAI_API_KEY is required` error was addressed by re-adding a dummy `OPENAI_API_KEY`. Now, I will re-execute the cell to initialize the `crewai` agents and crew with the specified Google Gemini LLM, expecting this to resolve the `ImportError` and allow the setup to complete.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bac8177"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous `ImportError: OPENAI_API_KEY is required` error was addressed by re-adding a dummy `OPENAI_API_KEY`. Now, I will re-execute the cell to initialize the `crewai` agents and crew with the specified Google Gemini LLM, expecting this to resolve the `ImportError` and allow the setup to complete.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "022d31a0"
      },
      "source": [
        "import os\n",
        "\n",
        "#os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "#os.environ['OPENAI_API_KEY'] = os.environ.get('OPENAI_API_KEY')\n",
        "os.environ['CREWAI_LLM'] = 'google-generative-ai'\n",
        "# Re-adding dummy key to resolve ImportError\n",
        "\n",
        "from crewai import Agent\n",
        "from crewai import Task\n",
        "from crewai import Crew\n",
        "from crewai import Process\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Initialize the Google Gemini LLM\n",
        "gemini_llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-pro\",\n",
        "    verbose=True,\n",
        "   temperature=0.7,\n",
        "   google_api_key=os.environ.get('GOOGLE_API_KEY')\n",
        ")\n",
        "\n",
        "architect_agent = Agent(\n",
        "  role='Senior Application architect',\n",
        "  goal='You are creating an architecture for a mobile/tablet based learning app called \"Autitalk\" with easy to use GUI that allows autistic children to talk to it, understand them as best as possible, provide visual options to them on what they actually require, then speak out the correct sentence, it can also prompt the child to say the sentense aloud or if it is too difficult, then with a tap of a button speak out the correct expression, like \"Mommy, I want to have some cereal now\"',\n",
        "  backstory='You are an expert application architect, who can provide architecture for complex software problems with AI on any platform. ',\n",
        "  llm=gemini_llm # Assign the Gemini LLM to the agent\n",
        ")\n",
        "\n",
        "# Create a task for the Architect\n",
        "architecting_task_1 = Task(\n",
        "  description='You are creating an architecture for a mobile/tablet based app with easy to use GUI that allows autistic children to talk to it, understand them as best as possible, provide visual options to them on what they actually require, then speak out the correct sentence, it can also prompt the child to say the sentence aloud or if it is too difficult, then with a tap of a button speak out the correct expression, like \"Mommy, I want to have some cereal now\". Provide the necessary, architecture, software components, tools required for development, provide it for review to the agent manager',\n",
        "  expected_output='Complete document on Overall architecture, tools, software modules, workflows, test execution, deployment mechanism for Android, iOS and how to run it on simulators for iOS on mac for testing, send it to manager_agent, upon receiving review comments from manager_agent, provide responses and incorporate the comments if found valid and send again to manager_agent for review and approval, repeat until no further comments are received from manager_agent and the architecture is approved.',\n",
        "  agent=architect_agent\n",
        ")\n",
        "\n",
        "# Create a manager to own the Autitalk project\n",
        "manager_agent = Agent(\n",
        "  role='Project Manager',\n",
        "  goal='Obtain the architecture provided by architect after architecting, review the architecture and provide feedback, run the project, upto demonstration to the user',\n",
        "  backstory='You are an accomplished manager with experience in decomposing architectures and creating teams for execution and deployment. You own the A utitalk project',\n",
        "  llm=gemini_llm # Assign the Gemini LLM to the agent\n",
        ")\n",
        "\n",
        "# Create a manager to own the Autitalk project\n",
        "manager_task_1 = Task(\n",
        "  description='You have multiple activities,1.initially critically review the aritecture obtained from the architect and provide feedback and repeat until the architecture is satisfactorily obtained. 2. The next task is estimating the crew skills required to execute the architecture. Context is you own the project for a mobile/tablet based learning app called \"Autitalk\" with easy to use GUI that allows autistic children to talk to it, understand them as best as possible, provide visual options to them on what they actually require, then speak out the correct sentence, it can also prompt the child to say the sentense aloud or if it is too difficult, then with a tap of a button speak out the correct expression, like \"Mommy, I want to have some cereal now\" ',\n",
        "  expected_output='Review the architecture from architect_agent, provide comments and wait for another version or explanation, then review again until it is certain that this is the best architecture. Then provide Google langchain_google_genai based code for creation of crew agents and task to execute the project architecture as decomposed by you also Once approved provide the compreshensive architecture in markdown format as the final output of this task',\n",
        "  agent=manager_agent\n",
        ")\n",
        "\n",
        "# The Crew \"pipes\" them in order\n",
        "my_crew = Crew(\n",
        "    agents=[architect_agent, manager_agent],\n",
        "    tasks=[architecting_task_1, manager_task_1],\n",
        "    llm=gemini_llm, # Assign the Gemini LLM to the entire crew\n",
        "    #process=Process.sequential\n",
        ")\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9c96f9ca",
        "outputId": "2a852f01-806f-429d-c497-11c450dffd3c"
      },
      "source": [
        "result = my_crew.kickoff()\n",
        "print(result)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### **Project Manager's Review and Approval**\n",
            "\n",
            "**To:** Senior Application Architect\n",
            "**From:** Project Manager\n",
            "**Subject:** RE: Architecture Proposal for \"Autitalk\" - Final Approval\n",
            "\n",
            "Dear Architect,\n",
            "\n",
            "Thank you for the revised architecture document (v1.1). I have completed my review, and I am pleased with the updates.\n",
            "\n",
            "The addition of the dedicated **Section 10 on Security, Privacy, and Compliance** and **Section 11 on a Phased Rollout & MVP Strategy** directly and effectively addresses the critical feedback from the initial review.\n",
            "\n",
            "*   The enhanced focus on data privacy provides a strong foundation for building trust with our users and ensuring we meet our legal and ethical obligations.\n",
            "*   The phased rollout plan is pragmatic and significantly de-risks the project. Starting with an MVP that leverages existing cloud services allows us to validate our core concept quickly, while the subsequent phases provide a clear roadmap for delivering advanced functionality and a superior user experience.\n",
            "\n",
            "The architecture is now comprehensive, robust, and aligned with our project goals. I am formally approving the **Autitalk Application Architecture Document v1.1**. We will proceed with this document as the blueprint for development.\n",
            "\n",
            "My next step is to decompose this architecture and assemble the execution team. Excellent work.\n",
            "\n",
            "Regards,\n",
            "Project Manager\n",
            "\n",
            "---\n",
            "\n",
            "### **Execution Crew and Task Delegation**\n",
            "\n",
            "Here is the plan for assembling the required crew and defining the initial set of tasks to execute Phase 1 (MVP) of the approved architecture. The following code defines the agents (our crew) and the tasks they will perform.\n",
            "\n",
            "```python\n",
            "# main.py\n",
            "# This script defines the crew and tasks for building the Autitalk MVP.\n",
            "\n",
            "from crewai import Agent, Task, Crew, Process\n",
            "from langchain_google_genai import ChatGoogleGenerativeAI\n",
            "\n",
            "# Initialize the LLM to be used by the agents\n",
            "# Replace with your actual API key setup\n",
            "# os.environ[\"GOOGLE_API_KEY\"] = \"YOUR_API_KEY\"\n",
            "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
            "\n",
            "# --- Define the Crew Agents ---\n",
            "\n",
            "# 1. UX/UI Designer Agent\n",
            "ux_ui_designer = Agent(\n",
            "    role='Lead UX/UI Designer',\n",
            "    goal='''Create an intuitive, accessible, and calming user interface for the Autitalk mobile app, \n",
            "            specifically tailored for children with autism spectrum disorder. The design must be simple, \n",
            "            predictable, and use high-contrast, clear visual elements.''',\n",
            "    backstory='''You are a highly empathetic designer with a specialization in creating applications \n",
            "                 for users with special needs. You understand the importance of avoiding sensory overload \n",
            "                 and creating a comforting digital environment. Your portfolio includes award-winning \n",
            "                 designs for educational and assistive technology.''',\n",
            "    verbose=True,\n",
            "    allow_delegation=False,\n",
            "    llm=llm\n",
            ")\n",
            "\n",
            "# 2. Mobile Lead Developer Agent\n",
            "mobile_lead_developer = Agent(\n",
            "    role='Lead Mobile Developer (Flutter)',\n",
            "    goal='''Develop a high-performance, cross-platform mobile application for Autitalk using Flutter, \n",
            "            based on the approved architecture and UX/UI designs. The app must be robust, responsive, and \n",
            "            effectively communicate with the backend services.''',\n",
            "    backstory='''You are a seasoned Flutter developer with extensive experience in building complex \n",
            "                 mobile applications from the ground up. You are an expert in state management (BLoC/Provider), \n",
            "                 API integration, and native device feature integration. You write clean, maintainable, \n",
            "                 and well-tested code.''',\n",
            "    verbose=True,\n",
            "    allow_delegation=True,\n",
            "    llm=llm\n",
            ")\n",
            "\n",
            "# 3. Backend Lead Developer Agent\n",
            "backend_lead_developer = Agent(\n",
            "    role='Lead Backend Developer (Python/FastAPI)',\n",
            "    goal='''Architect and build the scalable, secure, and efficient backend microservices for Autitalk \n",
            "            using Python and FastAPI. This includes the API Gateway, Authentication Service, and User \n",
            "            Profile Service for the MVP.''',\n",
            "    backstory='''You are a Python expert specializing in building high-performance APIs with FastAPI. \n",
            "                 You have a deep understanding of microservices architecture, cloud-native development, \n",
            "                 and database design (NoSQL). You prioritize security and scalability in all your work.''',\n",
            "    verbose=True,\n",
            "    allow_delegation=True,\n",
            "    llm=llm\n",
            ")\n",
            "\n",
            "# 4. AI/ML Engineer Agent\n",
            "ai_ml_engineer = Agent(\n",
            "    role='AI/ML Integration Engineer',\n",
            "    goal='''Integrate and configure the AI Core Service for the Autitalk MVP. This involves setting up \n",
            "            the pipeline to use AWS Transcribe for Speech-to-Text and AWS Polly for Text-to-Speech, \n",
            "            and implementing the basic intent recognition logic.''',\n",
            "    backstory='''You are a practical AI/ML engineer who excels at leveraging existing cloud AI services \n",
            "                 to deliver value quickly. You have hands-on experience with AWS services like Transcribe, \n",
            "                 Polly, and Lambda. Your focus for the MVP is on successful integration and creating a \n",
            "                 foundation for future custom model development.''',\n",
            "    verbose=True,\n",
            "    allow_delegation=False,\n",
            "    llm=llm\n",
            ")\n",
            "\n",
            "# 5. DevOps Engineer Agent\n",
            "devops_engineer = Agent(\n",
            "    role='Senior DevOps Engineer',\n",
            "    goal='''Establish a complete CI/CD pipeline and cloud infrastructure for the Autitalk project on AWS. \n",
            "            This includes containerizing backend services, setting up Kubernetes (EKS), and automating \n",
            "            the build and deployment processes for both the mobile app and backend.''',\n",
            "    backstory='''You are a master of Infrastructure as Code (IaC) and automation. You live and breathe \n",
            "                 Docker, Kubernetes, GitHub Actions, and AWS. Your mission is to ensure that the development \n",
            "                 team can ship code quickly, reliably, and with zero downtime.''',\n",
            "    verbose=True,\n",
            "    allow_delegation=False,\n",
            "    llm=llm\n",
            ")\n",
            "\n",
            "# 6. QA Lead Agent\n",
            "qa_lead = Agent(\n",
            "    role='Quality Assurance Lead',\n",
            "    goal='''Develop and execute a comprehensive testing strategy for the Autitalk MVP. This includes \n",
            "            creating plans for unit, integration, and end-to-end testing to ensure the application is \n",
            "            bug-free, reliable, and meets all architectural requirements.''',\n",
            "    backstory='''You are a meticulous QA professional with a passion for quality. You have a keen eye \n",
            "                 for detail and are skilled in both manual and automated testing methodologies. You understand \n",
            "                 the unique challenges of testing AI-driven applications and are committed to ensuring a \n",
            "                 flawless user experience.''',\n",
            "    verbose=True,\n",
            "    allow_delegation=False,\n",
            "    llm=llm\n",
            ")\n",
            "\n",
            "# --- Define the Tasks for MVP Execution ---\n",
            "\n",
            "# Task 1: UI/UX Design\n",
            "task_design = Task(\n",
            "    description='''Design the complete user flow and visual mockups for the Autitalk MVP. \n",
            "                   Focus on the \"Child Mode\" interface, including the main listening screen, \n",
            "                   the visual choice display, and the sentence articulation screen. Also, design \n",
            "                   the basic \"Guardian Mode\" for initial setup. Deliver high-fidelity mockups \n",
            "                   and a component style guide.''',\n",
            "    agent=ux_ui_designer,\n",
            "    expected_output=\"A complete set of high-fidelity mockups in Figma and a style guide document for the Autitalk MVP.\"\n",
            ")\n",
            "\n",
            "# Task 2: Backend Infrastructure and CI/CD Setup\n",
            "task_devops_setup = Task(\n",
            "    description='''Set up the foundational AWS infrastructure. This includes creating the EKS cluster, \n",
            "                   configuring the DynamoDB table for user profiles, and setting up the ECR repository. \n",
            "                   Create the initial CI/CD pipelines in GitHub Actions for the backend services.''',\n",
            "    agent=devops_engineer,\n",
            "    expected_output=\"A fully configured AWS environment and operational CI/CD pipeline for the backend.\"\n",
            ")\n",
            "\n",
            "# Task 3: Backend Services Development\n",
            "task_backend_dev = Task(\n",
            "    description='''Develop the core backend microservices for the MVP using Python/FastAPI. \n",
            "                   This includes:\n",
            "                   1. An API Gateway to route requests.\n",
            "                   2. An Authentication Service for guardian accounts.\n",
            "                   3. A User Profile Service to store basic user info.\n",
            "                   4. The initial AI Core Service skeleton.\n",
            "                   Ensure all services are containerized with Docker.''',\n",
            "    agent=backend_lead_developer,\n",
            "    context=[task_devops_setup],\n",
            "    expected_output=\"Dockerized FastAPI applications for all required backend services, with OpenAPI documentation.\"\n",
            ")\n",
            "\n",
            "# Task 4: AI Service Integration\n",
            "task_ai_integration = Task(\n",
            "    description='''Integrate AWS Transcribe and AWS Polly into the AI Core Service. \n",
            "                   The service must accept an audio file, send it to Transcribe, receive the text, \n",
            "                   perform simple keyword-based intent matching for the MVP's limited vocabulary, \n",
            "                   and use Polly to generate audio for the output sentence. The logic should be \n",
            "                   template-based as defined in the MVP strategy.''',\n",
            "    agent=ai_ml_engineer,\n",
            "    context=[task_backend_dev],\n",
            "    expected_output=\"A functional AI Core service endpoint that processes audio and returns sentence/visual options and output audio.\"\n",
            ")\n",
            "\n",
            "# Task 5: Mobile App Development\n",
            "task_mobile_dev = Task(\n",
            "    description='''Develop the Flutter mobile application for the MVP. Implement the UI based on \n",
            "                   the designs from the UX/UI designer. Build the audio capture module, API client to \n",
            "                   communicate with the backend, state management, and local caching for basic data. \n",
            "                   Integrate the native Text-to-Speech engine for sentence playback.''',\n",
            "    agent=mobile_lead_developer,\n",
            "    context=[task_design, task_ai_integration],\n",
            "    expected_output=\"A functional, cross-platform Flutter application (IPA and AAB builds) that implements the full MVP user workflow.\"\n",
            ")\n",
            "\n",
            "# Task 6: Quality Assurance and Testing\n",
            "task_qa = Task(\n",
            "    description='''Develop and execute the test plan for the entire MVP. Write unit tests for backend \n",
            "                   and mobile components. Perform integration tests between the mobile app and the backend. \n",
            "                   Conduct end-to-end tests for the core user workflow. Document all bugs and verify fixes.''',\n",
            "    agent=qa_lead,\n",
            "    context=[task_mobile_dev],\n",
            "    expected_output=\"A comprehensive test report detailing test cases, execution results, a list of all identified bugs, and a final sign-off for release.\"\n",
            ")\n",
            "\n",
            "\n",
            "# --- Instantiate and Run the Crew ---\n",
            "\n",
            "autitalk_crew = Crew(\n",
            "    agents=[ux_ui_designer, mobile_lead_developer, backend_lead_developer, ai_ml_engineer, devops_engineer, qa_lead],\n",
            "    tasks=[task_design, task_devops_setup, task_backend_dev, task_ai_integration, task_mobile_dev, task_qa],\n",
            "    process=Process.sequential,\n",
            "    verbose=2\n",
            ")\n",
            "\n",
            "# Kick off the project execution\n",
            "# result = autitalk_crew.kickoff()\n",
            "# print(\"######################\")\n",
            "# print(\"Autitalk MVP Development Plan Complete. Result:\")\n",
            "# print(result)\n",
            "```\n",
            "\n",
            "---\n",
            "\n",
            "### **Autitalk: Application Architecture Document v1.1 (Approved)**\n",
            "\n",
            "#### **1. Executive Summary**\n",
            "\n",
            "Autitalk is a mobile/tablet-based assistive communication and learning application designed for children with autism spectrum disorder (ASD). The app's core mission is to bridge the communication gap by interpreting a child's spoken attempts, offering visual choices to confirm intent, and articulating a well-formed sentence. This process not only facilitates immediate communication but also serves as a therapeutic tool to help children learn sentence structure and express their needs more clearly.\n",
            "\n",
            "This document details a scalable, cross-platform, AI-driven architecture to support Autitalk's vision.\n",
            "\n",
            "#### **2. Architectural Goals & Principles**\n",
            "\n",
            "*   **User-Centric & Accessible:** The UI/UX must be extremely simple, predictable, and calming. It should avoid overwhelming stimuli and be highly customizable to cater to individual sensory sensitivities and preferences.\n",
            "*   **AI-Powered Core:** The application's success hinges on its ability to accurately understand varied and non-typical speech patterns. Our AI models must be robust, adaptable, and continuously improvable.\n",
            "*   **Safety & Privacy First:** As the application will handle children's data, including voice recordings, we must adhere to the strictest privacy standards (e.g., COPPA, HIPAA considerations). All data must be encrypted in transit and at rest.\n",
            "*   **Cross-Platform:** The application must provide a consistent experience on both iOS and Android devices (phones and tablets).\n",
            "*   **Scalable & Maintainable:** The backend will be built on a microservices architecture to ensure that individual components can be scaled and updated independently.\n",
            "*   **Personalization:** The app must be deeply personalizable. A guardian should be able to add custom items (e.g., favorite foods, toys, family members' names) with corresponding images and vocabulary.\n",
            "\n",
            "#### **3. Overall Architecture Diagram**\n",
            "\n",
            "The system is designed with a client-server model. The mobile app serves as the client, and a set of cloud-based microservices provides the backend processing power, especially for the AI components.\n",
            "\n",
            "#### **4. Software Modules & Components**\n",
            "\n",
            "##### **4.1. Mobile Application (Client-Side)**\n",
            "\n",
            "The mobile application is the primary interface for the child and their guardian.\n",
            "\n",
            "*   **UI/UX Layer:**\n",
            "    *   **Description:** Manages all visual elements, animations, and user interactions. Built with large, clear, high-contrast visual components. Includes a \"Guardian Mode\" for configuration and a \"Child Mode\" for daily use.\n",
            "    *   **Components:** Home Screen, Listening/Interaction Screen, Visual Choice Display, Sentence Display, Guardian Dashboard.\n",
            "*   **Audio Processing Module:**\n",
            "    *   **Description:** Responsible for capturing high-quality audio from the device's microphone, performing basic noise reduction, and compressing it for efficient transmission to the backend.\n",
            "*   **State Management Module:**\n",
            "    *   **Description:** Manages the application's state, ensuring the UI is always in sync with the underlying data (e.g., user profile, interaction state).\n",
            "*   **API Client Module:**\n",
            "    *   **Description:** Handles all secure communication (RESTful APIs over HTTPS) with the backend services. Manages request/response cycles, authentication tokens, and error handling.\n",
            "*   **Local Storage (Persistence) Module:**\n",
            "    *   **Description:** Uses an embedded database (like SQLite) to store the user profile, custom vocabulary, cached images, and common phrases for offline access and faster performance.\n",
            "*   **Text-to-Speech (TTS) Module:**\n",
            "    *   **Description:** Utilizes the native device's TTS engine for speaking sentences. This allows for offline functionality and reduces latency. Can be augmented with higher-quality cloud-based voices when online.\n",
            "\n",
            "##### **4.2. Backend Services (Cloud-Side)**\n",
            "\n",
            "The backend is designed as a set of containerized microservices managed by an orchestrator.\n",
            "\n",
            "*   **API Gateway:**\n",
            "    *   **Description:** The single entry point for all client requests. It handles routing, authentication, rate limiting, and request logging.\n",
            "*   **Authentication Service:**\n",
            "    *   **Description:** Manages guardian user accounts, including registration, login, and password management using secure protocols like OAuth 2.0.\n",
            "*   **User Profile Service:**\n",
            "    *   **Description:** Stores and manages all user-specific data, including the child's profile, guardian information, and personalized vocabulary/image library (e.g., \"Mommy,\" \"Daddy,\" favorite cereal brand).\n",
            "*   **AI Core Service:**\n",
            "    *   **Description:** This is the brain of the application. It's a pipeline of machine learning models.\n",
            "        1.  **Speech-to-Text (STT):** Transcribes the child's audio into text. This model will be fine-tuned on datasets of atypical speech for higher accuracy.\n",
            "        2.  **Natural Language Understanding (NLU):** Analyzes the transcribed text to extract the core *intent* (e.g., `request_food`) and *entities* (e.g., `cereal`, `juice`).\n",
            "        3.  **Intent Disambiguation & Recommendation:** Based on the extracted intent/entities, this component queries the User Profile Service for context (e.g., child's favorite foods) and generates a set of probable visual options.\n",
            "        4.  **Sentence Generation:** Constructs grammatically correct sentences based on the user's final visual selection (e.g., `[Parent_Name]`, `I want to have some [Food_Item] now`).\n",
            "*   **Cloud Text-to-Speech (TTS) Service:**\n",
            "    *   **Description:** An optional, higher-quality voice generation service for generating audio clips for new or custom sentences.\n",
            "\n",
            "#### **5. Technology Stack & Tools**\n",
            "\n",
            "| Category                  | Technology / Tool                                                              | Justification                                                                                                 |\n",
            "| ------------------------- | ------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------- |\n",
            "| **Mobile Development**    | **Flutter & Dart**                                                             | High-performance, cross-platform framework for a consistent UI/UX on both iOS and Android from a single codebase. |\n",
            "| **State Management**        | **BLoC / Provider**                                                            | Robust and scalable state management patterns for Flutter.                                                    |\n",
            "| **Backend Framework**     | **Python (FastAPI)**                                                           | Python is the industry standard for AI/ML. FastAPI is modern, fast, and easy to use for building APIs.        |\n",
            "| **AI / Machine Learning** | **PyTorch / TensorFlow**                                                       | For building and training custom NLU models.                                                                  |\n",
            "|                           | **Cloud AI Services (AWS Transcribe, AWS Polly)**                              | To bootstrap STT and TTS capabilities. We will fine-tune these models with our own data for better accuracy. |\n",
            "| **Database**              | **Amazon DynamoDB or Firestore (NoSQL)**                                       | Flexible schema is ideal for storing user profiles and custom data. Scalable and fully managed.               |\n",
            "|                           | **SQLite (on-device)**                                                         | For local caching and offline functionality on the mobile app.                                                |\n",
            "| **Cloud Platform**        | **Amazon Web Services (AWS)**                                                  | Mature ecosystem with excellent AI/ML services (SageMaker, Transcribe), container support (EKS), and database options. |\n",
            "| **Containerization**      | **Docker & Kubernetes (Amazon EKS)**                                           | For packaging, deploying, and managing our backend microservices reliably and at scale.                       |\n",
            "| **Source Control**        | **Git (GitHub / GitLab)**                                                      | Industry standard for version control and collaboration.                                                      |\n",
            "| **CI/CD**                 | **GitHub Actions**                                                             | Tightly integrated with GitHub for automating build, test, and deployment pipelines for both mobile and backend. |\n",
            "\n",
            "#### **6. Core User Workflow**\n",
            "\n",
            "1.  **Initiation:** The child taps a large, friendly \"Talk to me\" button on the app's main screen.\n",
            "2.  **Audio Capture:** The app starts recording audio. The UI provides simple visual feedback (e.g., a pulsing circle) to indicate it's listening.\n",
            "3.  **API Request:** The captured audio file is sent securely to the backend API Gateway.\n",
            "4.  **AI Processing:**\n",
            "    *   The request is routed to the **AI Core Service**.\n",
            "    *   **STT** converts the audio to text (e.g., \"wan cewal\").\n",
            "    *   **NLU** identifies `intent: request_food` and `entity: cereal`.\n",
            "    *   The service fetches the user's profile to find preferred cereals (e.g., \"Cheerios,\" \"Fruit Loops\") and associated images.\n",
            "5.  **Visual Options:** The backend returns a list of ranked options (e.g., `{item: \"Cheerios\", image_url: \"...\", sentence: \"I want to have some Cheerios now\"}`).\n",
            "6.  **User Selection:** The mobile app displays these options as large, clear picture cards. The child taps the image of what they want (e.g., the Cheerios box).\n",
            "7.  **Sentence Articulation:** Upon selection, the app displays the full sentence: \"Mommy, I want to have some Cheerios now.\" It then presents two options:\n",
            "    *   **\"Say it with me\":** Prompts the child to repeat the sentence, potentially using the device's microphone to provide positive feedback.\n",
            "    *   **\"Say it for me\":** The app uses its TTS module to speak the sentence aloud in a clear, friendly voice.\n",
            "\n",
            "#### **7. Test Execution Strategy**\n",
            "\n",
            "*   **Unit Testing:** Each function/widget in the Flutter app and each endpoint/function in the backend services will have dedicated unit tests (using `pytest` for Python, `flutter_test` for Dart).\n",
            "*   **Integration Testing:** We will test the interaction between microservices (e.g., can the AI Core service correctly fetch data from the Profile service?).\n",
            "*   **End-to-End (E2E) Testing:** Using a framework like Appium or Flutter's `integration_test` package, we will automate full user workflows from tapping the listen button to the final sentence output.\n",
            "*   **AI Model Validation:** A \"golden dataset\" of audio clips with known intents will be used to continuously measure the accuracy, precision, and recall of our STT and NLU models.\n",
            "*   **Usability & User Acceptance Testing (UAT):** This is the most critical phase. We will work closely with child development specialists, therapists, and families with autistic children to test the app in real-world scenarios and gather qualitative feedback.\n",
            "\n",
            "#### **8. Deployment Mechanism (CI/CD)**\n",
            "\n",
            "We will use GitHub Actions to create separate, automated pipelines for the mobile app and the backend.\n",
            "\n",
            "**Backend Deployment:**\n",
            "1.  **On push to `main` branch:**\n",
            "2.  Run unit tests and linting.\n",
            "3.  Build Docker images for each microservice.\n",
            "4.  Push images to a container registry (Amazon ECR).\n",
            "5.  Deploy the new images to the Kubernetes cluster (EKS) using Helm charts for blue/green or canary deployments to ensure zero downtime.\n",
            "\n",
            "**Mobile App Deployment:**\n",
            "1.  **On push to `release` branch:**\n",
            "2.  **iOS:**\n",
            "    *   Job runs on a macOS runner.\n",
            "    *   Build the Flutter app for iOS (`.ipa` file).\n",
            "    *   Code-sign the application using secure credentials.\n",
            "    *   Upload the build to **TestFlight** for internal testing and UAT.\n",
            "    *   On approval, promote the build for App Store review and release.\n",
            "3.  **Android:**\n",
            "    *   Job runs on a Linux runner.\n",
            "    *   Build the Flutter app for Android (`.aab` file).\n",
            "    *   Sign the app bundle using secure credentials.\n",
            "    *   Upload the build to the **Google Play Console** internal testing track.\n",
            "    *   On approval, promote the build to production.\n",
            "\n",
            "#### **9. Running on Simulators for Testing**\n",
            "\n",
            "**iOS (on macOS):**\n",
            "1.  **Prerequisites:** A Mac computer with Xcode and CocoaPods installed.\n",
            "2.  **Setup:**\n",
            "    *   Clone the Git repository.\n",
            "    *   Navigate to the `ios` directory within the Flutter project (`cd ios`).\n",
            "    *   Run `pod install` to install iOS dependencies.\n",
            "    *   Open the `.xcworkspace` file in Xcode.\n",
            "3.  **Execution:**\n",
            "    *   In your IDE (VS Code or Android Studio), select an iOS Simulator from the device dropdown (e.g., \"iPhone 14 Pro\").\n",
            "    *   Run the Flutter application (`flutter run` or click the \"Run\" button). The app will be built and launched on the selected simulator.\n",
            "\n",
            "**Android (on macOS, Windows, or Linux):**\n",
            "1.  **Prerequisites:** Android Studio installed with the Android SDK and emulator set up.\n",
            "2.  **Setup:**\n",
            "    *   Open Android Studio.\n",
            "    *   Go to the Device Manager (formerly AVD Manager) and create a new Android Virtual Device (AVD) if one doesn't exist.\n",
            "3.  **Execution:**\n",
            "    *   In your IDE, select the desired Android Emulator from the device dropdown.\n",
            "    *   Start the emulator.\n",
            "    *   Run the Flutter application (`flutter run` or click \"Run\"). The app will be installed and launched on the running emulator.\n",
            "\n",
            "#### **10. Security, Privacy, and Compliance**\n",
            "\n",
            "Given the sensitive nature of the data being handled (children's voice and personal information), security and privacy are paramount.\n",
            "\n",
            "*   **Data Encryption:** All communication between the mobile client and backend services will be encrypted using TLS 1.2+. All user data at rest in the database and object storage will be encrypted using industry-standard AES-256 encryption.\n",
            "*   **Parental Consent:** The application will feature a clear, easy-to-understand consent form during onboarding. Guardians must provide explicit consent for data collection, especially for voice data that may be used for model training. Users will have the right to access and delete their data.\n",
            "*   **Data Anonymization:** Any voice data used for training our custom AI models will be fully anonymized and disassociated from any personally identifiable information (PII).\n",
            "*   **Compliance:** The system will be architected with **COPPA (Children's Online Privacy Protection Act)** and **HIPAA (Health Insurance Portability and Accountability Act)** guidelines in mind. This includes secure data handling, access controls, and audit trails. We will engage with legal counsel specializing in this area to ensure full compliance.\n",
            "*   **Authentication & Authorization:** The Guardian account will be protected by robust authentication. Access to the backend services will be strictly controlled via role-based access control (RBAC) and short-lived authentication tokens.\n",
            "\n",
            "#### **11. Phased Rollout & MVP Strategy**\n",
            "\n",
            "To mitigate risk and accelerate time-to-market, we will adopt a phased development and release strategy.\n",
            "\n",
            "*   **Phase 1: Minimum Viable Product (MVP)**\n",
            "    *   **Goal:** Validate the core user workflow and gather initial user feedback.\n",
            "    *   **Features:**\n",
            "        *   Core workflow with a limited, predefined set of intents (e.g., want food, want drink, want toy, need help).\n",
            "        *   Utilize standard AWS Transcribe for STT and AWS Polly for TTS.\n",
            "        *   Sentence generation will be based on simple, hardcoded templates.\n",
            "        *   No guardian-led personalization.\n",
            "        *   Online-only functionality.\n",
            "*   **Phase 2: Personalization & Data Foundation**\n",
            "    *   **Goal:** Enhance user engagement through personalization and begin building our unique dataset.\n",
            "    *   **Features:**\n",
            "        *   Introduce the Guardian Dashboard for adding custom nouns (people, foods, places) with uploaded images.\n",
            "        *   Implement the explicit consent flow for collecting anonymized voice data for model improvement.\n",
            "        *   Introduce basic offline capability by caching the user's personalized library on the device.\n",
            "*   **Phase 3: Advanced AI & Offline Mode**\n",
            "    *   **Goal:** Dramatically improve recognition accuracy for our target users and provide robust offline support.\n",
            "    *   **Features:**\n",
            "        *   Deploy our own fine-tuned STT and NLU models trained on the data collected in Phase 2.\n",
            "        *   Integrate on-device, lightweight STT/TTS models to provide a functional offline mode.\n",
            "        *   Explore more dynamic, context-aware sentence generation beyond simple templates.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[36m╭─\u001b[0m\u001b[36m──────────────────────────────────────────────\u001b[0m\u001b[36m \u001b[0m\u001b[1;36mExecution Traces\u001b[0m\u001b[36m \u001b[0m\u001b[36m───────────────────────────────────────────────\u001b[0m\u001b[36m─╮\u001b[0m\n",
              "\u001b[36m│\u001b[0m                                                                                                                 \u001b[36m│\u001b[0m\n",
              "\u001b[36m│\u001b[0m  \u001b[1;36m🔍 \u001b[0m\u001b[1;36mDetailed execution traces are available!\u001b[0m                                                                    \u001b[36m│\u001b[0m\n",
              "\u001b[36m│\u001b[0m                                                                                                                 \u001b[36m│\u001b[0m\n",
              "\u001b[36m│\u001b[0m  \u001b[37mView insights including:\u001b[0m                                                                                       \u001b[36m│\u001b[0m\n",
              "\u001b[36m│\u001b[0m  \u001b[94m  • Agent decision-making process\u001b[0m                                                                              \u001b[36m│\u001b[0m\n",
              "\u001b[36m│\u001b[0m  \u001b[94m  • Task execution flow and timing\u001b[0m                                                                             \u001b[36m│\u001b[0m\n",
              "\u001b[36m│\u001b[0m  \u001b[94m  • Tool usage details\u001b[0m                                                                                         \u001b[36m│\u001b[0m\n",
              "\u001b[36m│\u001b[0m                                                                                                                 \u001b[36m│\u001b[0m\n",
              "\u001b[36m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">╭─────────────────────────────────────────────── </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Execution Traces</span><span style=\"color: #008080; text-decoration-color: #008080\"> ────────────────────────────────────────────────╮</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">🔍 Detailed execution traces are available!</span>                                                                    <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">View insights including:</span>                                                                                       <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>  <span style=\"color: #0000ff; text-decoration-color: #0000ff\">  • Agent decision-making process</span>                                                                              <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>  <span style=\"color: #0000ff; text-decoration-color: #0000ff\">  • Task execution flow and timing</span>                                                                             <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>  <span style=\"color: #0000ff; text-decoration-color: #0000ff\">  • Tool usage details</span>                                                                                         <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Would you like to view your execution traces? [y/N] (20s timeout): "
          ]
        }
      ]
    }
  ]
}